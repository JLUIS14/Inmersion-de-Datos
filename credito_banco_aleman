

#INMERSION DE DATOS CON PYTHON

# prompt: importa los siguientes modulos con sus respectivos alias: pandas, matplotlib, seaborn, drive de google colab, warnings

# Importa los modulos
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from google.colab import drive
import warnings

drive.mount('/content/Drive')
warnings.filterwarnings('ignore')


pd.set_option('display.max_columns', None)
global df_banco, resultados

df_banco = pd.read_csv('/content/Drive/MyDrive/Inmersion/german_credit.csv')
df_banco.head()


df_banco.shape


df_banco.columns

df_banco.info()

df_banco.account_check_status.value_counts().index

columnas = list(df_banco.select_dtypes(include=['object']).columns)
columnas

columnas = list(df_banco.select_dtypes(include=['object']).columns)
for columna in columnas:
    print(f'El nombre de la column: {columna}')
    print(list(df_banco[f'{columna}'].value_counts().index))
    print('\n')

dic = {'yes': 1, 'no': 0}
df_banco['foreign_worker'] = df_banco['foreign_worker'].map(dic)
df_banco['foreign_worker']

def procesar_datos():
  global df_banco
  df_banco = df_banco.drop_duplicates() if df_banco.duplicated().any() else df_banco
  df_banco = df_banco.dropna() if df_banco.isnull().values.any() else df_banco

  a = {'no checking account': 4,
      '>= 200 DM / salary assignments for at least 1 year': 3,
      '0 <= ... < 200 DM': 2,
      '< 0 DM': 1
  }
  df_banco['account_check_status'] = df_banco['account_check_status'].map(a)

  a = { 'no credits taken/ all credits paid back duly' : 1,
      'all credits at this bank paid back duly' : 2,
      'existing credits paid back duly till now' : 3,
      'delay in paying off in the past' : 4,
      'critical account/ other credits existing (not at this bank)' : 5
  }
  df_banco['credit_history'] = df_banco['credit_history'].map(a)

  a = {'car (new)' : 1,
      'car (used)' : 2,
      'furniture/equipment' : 3,
      'radio/television' : 4,
      'domestic appliances' : 5,
      'repairs' : 6,
      'education' : 7,
      '(vacation - does not exist?)' : 8,
      'retraining' : 9,
      'business' : 10,
      'others' : 11
  }
  df_banco['purpose'] = df_banco['purpose'].map(a)

  a = {'unknown/ no savings account' : 1,
      '.. >= 1000 DM ' : 2,
      '500 <= ... < 1000 DM ' : 3,
      '100 <= ... < 500 DM' : 4,
      '... < 100 DM' : 5
  }
  df_banco['savings'] = df_banco['savings'].map(a)

  a = {'.. >= 7 years' : 1,
      '4 <= ... < 7 years' : 2,
      '1 <= ... < 4 years' : 3,
      '... < 1 year ' : 4,
      'unemployed' : 5
  }
  df_banco['present_emp_since'] = df_banco['present_emp_since'].map(a)

  a = {'male : divorced/separated' : 1,
      'female : divorced/separated/married' : 2,
      'male : single' : 3,
      'male : married/widowed' : 4,
      'female : single' : 5
  }
  df_banco['personal_status_sex'] = df_banco['personal_status_sex'].map(a)

  a = {'none' : 1,
      'co-applicant' : 2,
      'guarantor' : 3
  }
  df_banco['other_debtors'] = df_banco['other_debtors'].map(a)

  a = {'real estate' : 1,
      'if not A121 : building society savings agreement/ life insurance' : 2,
      'if not A121/A122 : car or other, not in attribute 6' : 3,
      'unknown / no property' : 4
  }
  df_banco['property'] = df_banco['property'].map(a)

  a = {'bank' : 1,
      'stores' : 2,
      'none' : 3
  }
  df_banco['other_installment_plans'] = df_banco['other_installment_plans'].map(a)

  a = {'rent' : 1,
      'own' : 2,
      'for free' : 3
  }
  df_banco['housing'] = df_banco['housing'].map(a)

  a = {'unemployed/ unskilled - non-resident' : 1,
      'unskilled - resident' : 2,
      'skilled employee / official' : 3,
      'management/ self-employed/ highly qualified employee/ officer' : 4
  }
  df_banco['job'] = df_banco['job'].map(a)

  a = {'yes, registered under the customers name ' : 1,
      'none' : 0
  }
  df_banco['telephone'] = df_banco['telephone'].map(a)


procesar_datos()
df_banco.sample(6)

variables_discretas = ['personal_status_sex', 'age', 'duration_in_month', 'credit_amount', 'default']
df_banco[variables_discretas].tail(5)

dic_sexo ={2:1, 5:1, 1:0, 3:0, 4:0}
df_banco['sexo'] = df_banco['personal_status_sex'].map(dic_sexo)


def feature_engineering():
  global df_banco
  dic_sexo = {2:1, 5:1, 1:0, 3:0, 4:0}
  dic_est_civil = {3:1, 5:1, 1:0, 2:0, 4:0}
  df_banco['sexo'] = df_banco['personal_status_sex'].map(dic_sexo)
  df_banco['estado_civil'] = df_banco['personal_status_sex'].map(dic_est_civil)
  df_banco['rango_edad'] = pd.cut(x = df_banco['age'],
                                  bins=[18, 30, 40, 50, 60, 70, 80],
                                  labels = [1, 2, 3, 4, 5, 6]).astype(int)
  df_banco['rango_plazos_credito']=pd.cut(x = df_banco['duration_in_month'],
                                            bins=[1, 12, 24, 36, 48, 60, 72],
                                            labels = [1, 2, 3, 4, 5, 6]).astype(int)
  df_banco['rango_valor_credito']=pd.cut(x = df_banco['credit_amount'],
                                           bins=[1, 1000, 2000, 3000, 4000,
                                                 5000, 6000, 7000, 8000, 9000,
                                                 10000, 11000, 12000, 13000,
                                                 14000, 15000, 16000, 17000,
                                                 18000, 19000, 20000],
                                           labels = [1, 2, 3, 4, 5, 6, 7, 8, 9,
                                                     10, 11, 12, 13, 14, 15, 16,
                                                     17, 18, 19, 20]).astype(int)
  df_banco = df_banco.drop(columns=['personal_status_sex','age',
                                    'duration_in_month','credit_amount'])

feature_engineering()
df_banco.head(5)

df_banco.describe()


# Suponiendo que df_banco ya está definido y contiene una columna 'sexo'
# Vamos a crear el histograma

plt.figure(figsize=(10, 6))  # Tamaño de la figura
sns.histplot(df_banco['sexo'], bins=3, kde=False)  # Histograma con seaborn

plt.title('Histograma de la Variable "Sexo"')
plt.xlabel('Sexo')
plt.ylabel('Frecuencia')
plt.xticks(ticks=[0, 1], labels=['Femenino', 'Masculino'])  # Ajustar etiquetas si los valores son 0 y 1
plt.grid(True)

plt.show()


def analisis_exploratorio():
  global df_banco
  histogramas = ['sexo','estado_civil','rango_plazos_credito','rango_edad','default']
  lista_histogramas = list(enumerate(histogramas))
  plt.figure(figsize = (30,20))
  plt.title('Histogramas')
  for i in lista_histogramas:
    plt.subplot(3, 2, i[0]+1)
    sns.countplot(x = i[1], data = df_banco)
    plt.xlabel(i[1], fontsize=20)
    plt.ylabel('Total', fontsize=20)

analisis_exploratorio()

analizar los datos de las distribuciones e identificar si hay algun valor o registro que no se debe considerar en el modelo

como hacer un mapa de calor investigar y como crear, para entender un comportamiento entre una variable y la otra y decir cuales de las variables van ha impactar mas.

crear una conclusion para cada histograma

def visualizar_histogramas(df_banco):
    histogramas = ['sexo','estado_civil','rango_plazos_credito','rango_edad','default']
    plt.figure(figsize = (30,20))
    plt.suptitle('Histogramas de Variables Categóricas', fontsize=30)
    for idx, col in enumerate(histogramas):
        plt.subplot(3, 2, idx+1)
        sns.countplot(x = col, data = df_banco)
        plt.xlabel(col, fontsize=20)
        plt.ylabel('Total', fontsize=20)
    plt.show()

visualizar_histogramas(df_banco)

def visualizar_boxplots(df_banco):
    # Calculate the number of rows needed for subplots
    num_cols = len(df_banco.select_dtypes(include=['number']).columns)
    num_rows = (num_cols + 1) // 2  # Calculate the number of rows required

    plt.figure(figsize = (60,30))
    plt.suptitle('Boxplots de Variables Numéricas', fontsize=30)
    for idx, col in enumerate(df_banco.select_dtypes(include=['number']).columns):
        # Use num_rows in the subplot grid definition
        plt.subplot(num_rows, 2, idx+1)
        sns.boxplot(y = col, data = df_banco)
        plt.xlabel(col, fontsize=20)
    plt.show()

visualizar_boxplots(df_banco)

def mostrar_estadisticas_descriptivas(df_banco):
    print(df_banco.describe())

mostrar_estadisticas_descriptivas(df_banco)

def analizar_valores_faltantes(df_banco):
    missing_values = df_banco.isnull().sum()
    print(f'Valores faltantes en el DataFrame:\n{missing_values}')

analizar_valores_faltantes(df_banco)

def analizar_correlacion(df_banco):
    plt.figure(figsize=(20,10))
    sns.heatmap(df_banco.corr(), annot=True, cmap='coolwarm', linewidths=0.5)
    plt.title('Matriz de Correlación', fontsize=20)
    plt.show()

analizar_correlacion(df_banco)

import pandas as pd

# Asumiendo que df_banco ya está definido

# Calcular los cuartiles y el IQR para cada columna numérica
Q1 = df_banco.quantile(0.25)
Q3 = df_banco.quantile(0.75)
IQR = Q3 - Q1

# Definir los límites inferior y superior
lower_bound = Q1 - 1.5 * IQR
upper_bound = Q3 + 1.5 * IQR

# Filtrar los datos eliminando los outliers
df_banco_sin_outliers = df_banco[~((df_banco < lower_bound) | (df_banco > upper_bound)).any(axis=1)]

# Mostrar las primeras filas del DataFrame sin outliers
print(df_banco_sin_outliers.head())


from scipy import stats
import numpy as np

# Calcular el Z-score para cada columna numérica
z_scores = np.abs(stats.zscore(df_banco.select_dtypes(include=[np.number])))

# Definir un umbral para identificar los outliers (típicamente 3)
threshold = 3

# Filtrar los datos eliminando los outliers
df_banco_sin_outliers = df_banco[(z_scores < threshold).all(axis=1)]

# Mostrar las primeras filas del DataFrame sin outliers
print(df_banco_sin_outliers.head())


plt.figure(figsize=(30,10))
heatmap = sns.heatmap(df_banco.corr(), annot=True, cmap='coolwarm', fmt='.2f')
plt.title('Mapa de calor de Correlaciones', fontsize=18)
plt.show()

# prompt: importar las siguientes bibliotecas: train_test_split, logisticRegression, DecisionTreeClassifier, RandomForestClassifier, GaussianNB, accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, roc_curve

from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, roc_curve
from sklearn.metrics import confusion_matrix
from sklearn.metrics import ConfusionMatrixDisplay

# prompt: por favor generame un modelo de machine learning de clasificacion en phyton

# Dividir los datos en conjuntos de entrenamiento y prueba
X = df_banco.drop('default', axis=1)
y = df_banco['default']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Inicializar y entrenar un modelo de Regresión Logística
model = LogisticRegression()
model.fit(X_train, y_train)

# Hacer predicciones en el conjunto de prueba
y_pred = model.predict(X_test)

# Evaluar el modelo
accuracy = accuracy_score(y_test, y_pred)
precision = precision_score(y_test, y_pred)
recall = recall_score(y_test, y_pred)
f1 = f1_score(y_test, y_pred)

print("Accuracy:", accuracy)
print("Precision:", precision)
print("Recall:", recall)
print("F1-score:", f1)


#@title



def crea_modelos():
  global df_banco, resultados
  y = df_banco['default']
  X = df_banco.drop(columns = 'default')
  train_x, test_x, train_y, test_y = train_test_split(X, y, test_size=0.30, random_state=77)

  models = {
      'Regresion Logistica': LogisticRegression(),
      'Arbol de Decision': DecisionTreeClassifier(),
      'Random Forest': RandomForestClassifier(),
      'Naive Bayes': GaussianNB()
  }
  results ={'Model': [], 'Accuracy': [], 'Precision': [], 'Recall': [], 'F1-Score': [], 'AUC-ROC': []}
  
  for name, model in models.items():
    model.fit(train_x, train_y)
    predictions = model.predict(test_x)
    accuracy = accuracy_score(test_y, predictions)
    precision = precision_score(test_y, predictions)
    recall = recall_score(test_y, predictions)
    f1 = f1_score(test_y, predictions)
    roc_auc = roc_auc_score(test_y, predictions)


    if hasattr(model, 'predict_proba'):
      proba = model.predict_proba(test_x)
      roc_auc = roc_auc_score(test_y, proba[:, 1])
    else:
      roc_auc = None
    results['Model'].append(name)
    results['Accuracy'].append(accuracy)
    results['Precision'].append(precision)
    results['Recall'].append(recall)
    results['F1-Score'].append(f1)
    results['AUC-ROC'].append(roc_auc)
    
    # Generar y mostrar la matriz de confusión
    conf_matrix = confusion_matrix(test_y, predictions)
    print(f"Matriz de Confusión para {name}:\n", conf_matrix)

    disp = ConfusionMatrixDisplay(confusion_matrix=conf_matrix, display_labels=['No Default', 'Default'])
    disp.plot(cmap=plt.cm.Blues)
    plt.title(f'Matriz de Confusión - {name}')
    plt.show()

  resultados = results
  

crea_modelos()
for i, model in enumerate(resultados['Model']):
  print(model)
  print(resultados['Accuracy'][i])
  print(resultados['Precision'][i])
  print(resultados['Recall'][i])
  print(resultados['F1-Score'][i])
  print(resultados['AUC-ROC'][i])
  
  print('\n')


# prompt: como generar un grafico de barra a partir de un dataframe

import matplotlib.pyplot as plt

# Supongamos que 'resultados' es tu DataFrame
# y quieres graficar la precisión de cada modelo

plt.bar(resultados['Model'], resultados['Precision'])
plt.xlabel('Modelo')
plt.ylabel('Precisión')
plt.title('Precisión de los Modelos')
plt.xticks(rotation=45, ha='right')  # Rotar etiquetas del eje x para mejor legibilidad
plt.tight_layout()  # Ajustar el diseño para evitar solapamientos
plt.show()


def visualiza_resultados():
    global df_banco, resultados
    results_df = pd.DataFrame(resultados)
    results_df.set_index('Model', inplace=True)

    results_df =results_df.T
    colors = ['#0077b6', '#CDDBF3', '#2ca02c', '#d62728']
    
    results_df.plot(kind='bar', figsize=(12, 6), colormap='viridis', rot=0, color=colors)
    plt.title('Comparación de Métricas por Modelo')
    plt.xlabel('Métricas')
    plt.ylabel('puntuacion')
    plt.legend(title='Modelos')
    plt.tight_layout()
    plt.show()

    from IPython.display import HTML, display

    texto = 'cual de estos modelos seleccionarias y porque'
    display(HTML(f'<div style="text-align: center;">{texto}</div>'))
    display(results_df)

visualiza_resultados()

Questions: como se trata la matriz de confusion: se analiza de acuerdo a los resultados de las cantidades de verdaderos positivos y verdaderos negativos los cuales nos indican que las predicciones son las correctas, mientras que los falsos positivos y los falsos negativos nos indican que hay errores en la prediccion del modelo aplicado. cual es la variable respuesta que debemos tener en cuenta para obtener la respuesta?, son los Ture Positivo y los True Negativos. eso esta desarrollado y se muestra en los graficos de las matriz de confusion de cada modelo.



